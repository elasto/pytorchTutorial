{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","metadata":{},"source":["Everything in pytorch is based on Tensor operations.<br>\n","A tensor can have different dimensions<br>\n","so it can be 1d, 2d, or even 3d and higher"]},{"cell_type":"markdown","metadata":{},"source":["scalar, vector, matrix, tensor"]},{"cell_type":"markdown","metadata":{},"source":["torch.empty(size): uninitiallized"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.empty(1) # scalar\n","print(x)\n","x = torch.empty(3) # vector, 1D\n","print(x)\n","x = torch.empty(2,3) # matrix, 2D\n","print(x)\n","x = torch.empty(2,2,3) # tensor, 3 dimensions\n","#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n","print(x)"]},{"cell_type":"markdown","metadata":{},"source":["torch.rand(size): random numbers [0, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.rand(5, 3)\n","print(x)"]},{"cell_type":"markdown","metadata":{},"source":["torch.zeros(size), fill with 0<br>\n","torch.ones(size), fill with 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.zeros(5, 3)\n","print(x)"]},{"cell_type":"markdown","metadata":{},"source":["check size"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(x.size())"]},{"cell_type":"markdown","metadata":{},"source":["check data type"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(x.dtype)"]},{"cell_type":"markdown","metadata":{},"source":["specify types, float32 default"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.zeros(5, 3, dtype=torch.float16)\n","print(x)"]},{"cell_type":"markdown","metadata":{},"source":["check type"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(x.dtype)"]},{"cell_type":"markdown","metadata":{},"source":["construct from data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.tensor([5.5, 3])\n","print(x.size())"]},{"cell_type":"markdown","metadata":{},"source":["requires_grad argument<br>\n","This will tell pytorch that it will need to calculate the gradients for this tensor<br>\n","later in your optimization steps<br>\n","i.e. this is a variable in your model that you want to optimize"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.tensor([5.5, 3], requires_grad=True)"]},{"cell_type":"markdown","metadata":{},"source":["Operations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = torch.rand(2, 2)\n","x = torch.rand(2, 2)"]},{"cell_type":"markdown","metadata":{},"source":["elementwise addition"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["z = x + y\n","# torch.add(x,y)"]},{"cell_type":"markdown","metadata":{},"source":["in place addition, everythin with a trailing underscore is an inplace operation<br>\n","i.e. it will modify the variable<br>\n","y.add_(x)"]},{"cell_type":"markdown","metadata":{},"source":["substraction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["z = x - y\n","z = torch.sub(x, y)"]},{"cell_type":"markdown","metadata":{},"source":["multiplication"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["z = x * y\n","z = torch.mul(x,y)"]},{"cell_type":"markdown","metadata":{},"source":["division"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["z = x / y\n","z = torch.div(x,y)"]},{"cell_type":"markdown","metadata":{},"source":["Slicing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.rand(5,3)\n","print(x)\n","print(x[:, 0]) # all rows, column 0\n","print(x[1, :]) # row 1, all columns\n","print(x[1,1]) # element at 1, 1"]},{"cell_type":"markdown","metadata":{},"source":["Get the actual value if only 1 element in your tensor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(x[1,1].item())"]},{"cell_type":"markdown","metadata":{},"source":["Reshape with torch.view()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n","# if -1 it pytorch will automatically determine the necessary size\n","print(x.size(), y.size(), z.size())"]},{"cell_type":"markdown","metadata":{},"source":["Numpy<br>\n","Converting a Torch Tensor to a NumPy array and vice versa is very easy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = torch.ones(5)\n","print(a)"]},{"cell_type":"markdown","metadata":{},"source":["torch to numpy with .numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["b = a.numpy()\n","print(b)\n","print(type(b))"]},{"cell_type":"markdown","metadata":{},"source":["Carful: If the Tensor is on the CPU (not the GPU),<br>\n","both objects will share the same memory location, so changing one<br>\n","will also change the other"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a.add_(1)\n","print(a)\n","print(b)"]},{"cell_type":"markdown","metadata":{},"source":["numpy to torch with .from_numpy(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","print(a)\n","print(b)"]},{"cell_type":"markdown","metadata":{},"source":["again be careful when modifying"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a += 1\n","print(a)\n","print(b)"]},{"cell_type":"markdown","metadata":{},"source":["by default all tensors are created on the CPU,<br>\n","but you can also move them to the GPU (only if it's available )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    z = x + y\n","    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n","    # move to CPU again\n","    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n","    # z = z.numpy()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.7 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"fab6491ffa57cde399abf637ad0d7a1f2ca8c908d020920dd5079587bbd23a3b"}}},"nbformat":4,"nbformat_minor":2}
