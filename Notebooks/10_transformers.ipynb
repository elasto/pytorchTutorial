{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Transforms can be applied to PIL images, tensors, ndarrays, or custom data<br>\n", "during creation of the DataSet<br>\n", "complete list of built-in transforms: <br>\n", "https://pytorch.org/docs/stable/torchvision/transforms.html<br>\n", "On Images<br>\n", "---------<br>\n", "CenterCrop, Grayscale, Pad, RandomAffine<br>\n", "RandomCrop, RandomHorizontalFlip, RandomRotation<br>\n", "Resize, Scale<br>\n", "On Tensors<br>\n", "----------<br>\n", "LinearTransformation, Normalize, RandomErasing<br>\n", "Conversion<br>\n", "----------<br>\n", "ToPILImage: from tensor or ndrarray<br>\n", "ToTensor : from numpy.ndarray or PILImage<br>\n", "Generic<br>\n", "-------<br>\n", "Use Lambda <br>\n", "Custom<br>\n", "------<br>\n", "Write own class<br>\n", "Compose multiple Transforms<br>\n", "---------------------------<br>\n", "composed = transforms.Compose([Rescale(256),<br>\n", "                               RandomCrop(224)])<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torchvision\n", "from torch.utils.data import Dataset\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WineDataset(Dataset):\n", "    def __init__(self, transform=None):\n", "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n", "        self.n_samples = xy.shape[0]\n\n", "        # note that we do not convert to tensor here\n", "        self.x_data = xy[:, 1:]\n", "        self.y_data = xy[:, [0]]\n", "        self.transform = transform\n", "    def __getitem__(self, index):\n", "        sample = self.x_data[index], self.y_data[index]\n", "        if self.transform:\n", "            sample = self.transform(sample)\n", "        return sample\n", "    def __len__(self):\n", "        return self.n_samples"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Custom Transforms<br>\n", "implement __call__(self, sample)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ToTensor:\n", "    # Convert ndarrays to Tensors\n", "    def __call__(self, sample):\n", "        inputs, targets = sample\n", "        return torch.from_numpy(inputs), torch.from_numpy(targets)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class MulTransform:\n", "    # multiply inputs with a given factor\n", "    def __init__(self, factor):\n", "        self.factor = factor\n", "    def __call__(self, sample):\n", "        inputs, targets = sample\n", "        inputs *= self.factor\n", "        return inputs, targets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Without Transform')\n", "dataset = WineDataset()\n", "first_data = dataset[0]\n", "features, labels = first_data\n", "print(type(features), type(labels))\n", "print(features, labels)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\nWith Tensor Transform')\n", "dataset = WineDataset(transform=ToTensor())\n", "first_data = dataset[0]\n", "features, labels = first_data\n", "print(type(features), type(labels))\n", "print(features, labels)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\nWith Tensor and Multiplication Transform')\n", "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n", "dataset = WineDataset(transform=composed)\n", "first_data = dataset[0]\n", "features, labels = first_data\n", "print(type(features), type(labels))\n", "print(features, labels)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}