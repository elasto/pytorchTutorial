{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n 3 DIFFERENT METHODS TO REMEMBER:<br>\n", " - torch.save(arg, PATH) # can be model, tensor, or dictionary<br>\n", " - torch.load(PATH)<br>\n", " - torch.load_state_dict(arg)<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n 2 DIFFERENT WAYS OF SAVING<br>\n", "# 1) lazy way: save whole model<br>\n", "torch.save(model, PATH)<br>\n", "# model class must be defined somewhere<br>\n", "model = torch.load(PATH)<br>\n", "model.eval()<br>\n", "# 2) recommended way: save only the state_dict<br>\n", "torch.save(model.state_dict(), PATH)<br>\n", "# model must be created again with parameters<br>\n", "model = Model(*args, **kwargs)<br>\n", "model.load_state_dict(torch.load(PATH))<br>\n", "model.eval()<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Model(nn.Module):\n", "    def __init__(self, n_input_features):\n", "        super(Model, self).__init__()\n", "        self.linear = nn.Linear(n_input_features, 1)\n", "    def forward(self, x):\n", "        y_pred = torch.sigmoid(self.linear(x))\n", "        return y_pred"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = Model(n_input_features=6)\n", "# train your model..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["##################save all ######################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for param in model.parameters():\n", "    print(param)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["save and load entire model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["FILE = \"model.pth\"\n", "torch.save(model, FILE)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loaded_model = torch.load(FILE)\n", "loaded_model.eval()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for param in loaded_model.parameters():\n", "    print(param)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##########save only state dict #########################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["save only state dict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["FILE = \"model.pth\"\n", "torch.save(model.state_dict(), FILE)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(model.state_dict())\n", "loaded_model = Model(n_input_features=6)\n", "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n", "loaded_model.eval()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(loaded_model.state_dict())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#########load checkpoint#####################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["learning_rate = 0.01\n", "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["checkpoint = {\n", "\"epoch\": 90,\n", "\"model_state\": model.state_dict(),\n", "\"optim_state\": optimizer.state_dict()\n", "}\n", "print(optimizer.state_dict())\n", "FILE = \"checkpoint.pth\"\n", "torch.save(checkpoint, FILE)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = Model(n_input_features=6)\n", "optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["checkpoint = torch.load(FILE)\n", "model.load_state_dict(checkpoint['model_state'])\n", "optimizer.load_state_dict(checkpoint['optim_state'])\n", "epoch = checkpoint['epoch']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.eval()\n", "# - or -\n", "# model.train()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(optimizer.state_dict())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Remember that you must call model.eval() to set dropout and batch normalization layers <br>\n", "to evaluation mode before running inference. Failing to do this will yield <br>\n", "inconsistent inference results. If you wish to resuming training, <br>\n", "call model.train() to ensure these layers are in training mode."]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n SAVING ON GPU/CPU <br>\n", "# 1) Save on GPU, Load on CPU<br>\n", "device = torch.device(\"cuda\")<br>\n", "model.to(device)<br>\n", "torch.save(model.state_dict(), PATH)<br>\n", "device = torch.device('cpu')<br>\n", "model = Model(*args, **kwargs)<br>\n", "model.load_state_dict(torch.load(PATH, map_location=device))<br>\n", "# 2) Save on GPU, Load on GPU<br>\n", "device = torch.device(\"cuda\")<br>\n", "model.to(device)<br>\n", "torch.save(model.state_dict(), PATH)<br>\n", "model = Model(*args, **kwargs)<br>\n", "model.load_state_dict(torch.load(PATH))<br>\n", "model.to(device)<br>\n", "# Note: Be sure to use the .to(torch.device('cuda')) function <br>\n", "# on all model inputs, too!<br>\n", "# 3) Save on CPU, Load on GPU<br>\n", "torch.save(model.state_dict(), PATH)<br>\n", "device = torch.device(\"cuda\")<br>\n", "model = Model(*args, **kwargs)<br>\n", "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want<br>\n", "model.to(device)<br>\n", "# This loads the model to a given GPU device. <br>\n", "# Next, be sure to call model.to(torch.device('cuda')) to convert the model\u00e2\u20ac\u2122s parameter tensors to CUDA tensors<br>\n", ""]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}