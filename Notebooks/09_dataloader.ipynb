{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torchvision\n", "from torch.utils.data import Dataset, DataLoader\n", "import numpy as np\n", "import math"]}, {"cell_type": "markdown", "metadata": {}, "source": ["gradient computation etc. not efficient for whole data set<br>\n", "-> divide dataset into small batches"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "# training loop<br>\n", "for epoch in range(num_epochs):<br>\n", "    # loop over all batches<br>\n", "    for i in range(total_batches):<br>\n", "        batch_x, batch_y = ...<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["epoch = one forward and backward pass of ALL training samples<br>\n", "batch_size = number of training samples used in one forward/backward pass<br>\n", "number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes<br>\n", "e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--> DataLoader can do the batch computation for us"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Implement a custom Dataset:<br>\n", "inherit Dataset<br>\n", "implement __init__ , __getitem__ , and __len__"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WineDataset(Dataset):\n", "    def __init__(self):\n", "        # Initialize data, download, etc.\n", "        # read with numpy or pandas\n", "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n", "        self.n_samples = xy.shape[0]\n\n", "        # here the first column is the class label, the rest are the features\n", "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n", "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n\n", "    # support indexing such that dataset[i] can be used to get i-th sample\n", "    def __getitem__(self, index):\n", "        return self.x_data[index], self.y_data[index]\n\n", "    # we can call len(dataset) to return the size\n", "    def __len__(self):\n", "        return self.n_samples"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset = WineDataset()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["get first sample and unpack"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["first_data = dataset[0]\n", "features, labels = first_data\n", "print(features, labels)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load whole dataset with DataLoader<br>\n", "shuffle: shuffle data, good for training<br>\n", "num_workers: faster loading with multiple subprocesses<br>\n", "!!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = DataLoader(dataset=dataset,\n", "                          batch_size=4,\n", "                          shuffle=True,\n", "                          num_workers=2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["convert to an iterator and look at one random sample"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataiter = iter(train_loader)\n", "data = dataiter.next()\n", "features, labels = data\n", "print(features, labels)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dummy Training loop"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_epochs = 2\n", "total_samples = len(dataset)\n", "n_iterations = math.ceil(total_samples/4)\n", "print(total_samples, n_iterations)\n", "for epoch in range(num_epochs):\n", "    for i, (inputs, labels) in enumerate(train_loader):\n", "        \n", "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n", "        # Run your training process\n", "        if (i+1) % 5 == 0:\n", "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["some famous datasets are available in torchvision.datasets<br>\n", "e.g. MNIST, Fashion-MNIST, CIFAR10, COCO"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset = torchvision.datasets.MNIST(root='./data', \n", "                                           train=True, \n", "                                           transform=torchvision.transforms.ToTensor(),  \n", "                                           download=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = DataLoader(dataset=train_dataset, \n", "                                           batch_size=3, \n", "                                           shuffle=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["look at one random sample"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataiter = iter(train_loader)\n", "data = dataiter.next()\n", "inputs, targets = data\n", "print(inputs.shape, targets.shape)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}